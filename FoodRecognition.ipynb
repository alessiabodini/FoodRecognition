{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "path = Path(os.path.join('C:/', 'Users', 'ale19', 'Downloads', 'Food-101'))\n",
    "path_h5 = path\n",
    "path_img = path/'images'\n",
    "path_meta = path/'meta/meta'\n",
    "path_working = '/kaggle/working/'\n",
    "\n",
    "# Modify the from folder function in fast.ai to use the dictionary mapping from folder to space seperated labels\n",
    "def label_from_folder_map(class_to_label_map):\n",
    "    return lambda o: class_to_label_map[(o.parts if isinstance(o, Path) else o.split(os.path.sep))[-2]]\n",
    "\n",
    "# Develop dictionary mapping from classes to labels\n",
    "classes = pd.read_csv(path_meta/'classes.txt', header=None, index_col=0)\n",
    "classes_list = classes.index.tolist()\n",
    "labels = pd.read_csv(path_meta/'labels.txt', header=None)\n",
    "classes['map'] = labels[0].values\n",
    "classes_to_labels_map = classes['map'].to_dict()\n",
    "label_from_folder_food_func = label_from_folder_map(classes_to_labels_map)\n",
    "\n",
    "# Setup the training set of images\n",
    "train_df = pd.read_csv(path_meta/'train.txt', header=None).apply(lambda x : x + '.jpg')\n",
    "train_set = dict((c, []) for c in classes_list)\n",
    "for i in range(len(train_df)):\n",
    "    train_set[Path(train_df[0][i]).parts[-2]].append(train_df[0][i])\n",
    "\n",
    "# Setup the testing set of images\n",
    "test_df = pd.read_csv(path_meta/'test.txt', header=None).apply(lambda x : x + '.jpg')\n",
    "test_set = dict((c, []) for c in classes_list)\n",
    "for i in range(len(test_df)):\n",
    "    test_set[Path(test_df[0][i]).parts[-2]].append(train_df[0][i])\n",
    "    \n",
    "#img = Image.open(os.path.join(path_img, test_set['apple_pie'][1]))\n",
    "#plt.imshow(np.array(img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from resnet import FeaturesExtractor\n",
    "import cv2\n",
    "\n",
    "def extractFeatures(t_set, n_images):\n",
    "\n",
    "    # Extractor initialization\n",
    "    extractor = FeaturesExtractor()\n",
    "\n",
    "    # Infer from all images (or until one is reached)\n",
    "    n_features = 2048\n",
    "    features = np.zeros((n_images, n_features+1), dtype=object) # in the first column there is the image's name\n",
    "    idx = -1\n",
    "    for c in t_set:\n",
    "        print(c)\n",
    "        img_list = []\n",
    "        for name in t_set[c]:\n",
    "            #print(idx)\n",
    "            idx += 1\n",
    "            features[idx][0] = name\n",
    "            img = cv2.imread(os.path.join(path_img, name))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img,(128,128))\n",
    "            # img_list size has to be (N,W,H,C), output has size (N,2048)\n",
    "            features[idx,1:] = extractor.getFeaturesOfList(np.stack(img_list))\n",
    "        if c == 'apple_pie': # ONLY THE FIRST 3 CLASSES\n",
    "            break\n",
    "\n",
    "    print(features[:10,:])\n",
    "            \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect the features for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1a0c910ca30b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrain_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_features.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_images' is not defined"
     ]
    }
   ],
   "source": [
    "n_features = 2048\n",
    "\n",
    "n_images_per_class = len(list(train_set.keys())[0])\n",
    "n_images = len(train_set) * n_images_per_class     \n",
    "if os.path.isfile('train_features.txt'):\n",
    "    idx = 0\n",
    "    train_feat = np.zeros((n_images, n_features+1), dtype=object)\n",
    "    with open('train_features.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            train_feat[idx,0] = line.split()[0]\n",
    "            train_feat[idx,1:] = line.split()[1:]\n",
    "            idx += 1\n",
    "else:\n",
    "    train_feat = extractFeatures(train_set, n_images)\n",
    "    \n",
    "n_images_per_class = len(list(train_set.keys())[0])\n",
    "n_images = len(train_set) * n_images_per_class     \n",
    "if os.path.isfile('test_features.txt'):\n",
    "    idx = 0\n",
    "    n_images_per_class = len(list(test_set.keys())[0])\n",
    "    n_images = len(test_set) * n_images_per_class \n",
    "    test_feat = np.zeros((n_images, n_features+1), dtype=object)\n",
    "    with open('test_features.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            test_feat[idx,0] = line.split()[0]\n",
    "            test_feat[idx,1:] = line.split()[1:]\n",
    "            idx += 1\n",
    "else:\n",
    "    test_feat = extractFeatures(test_set, n_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Set the parameters: K is the number of clostes neighbours to consider and fun is the metric chosen\n",
    "K = 1\n",
    "fun = 'euclidean'\n",
    "\n",
    "# 2. Calculate the distance between train objects and test objects \n",
    "D = cdist(x_train, x_test, metric=fun)\n",
    "\n",
    "#print(D.shape)\n",
    "\n",
    "# 3. Per ogni dato di test (argomento axis=0), ordino le distanze dalla più piccola alla più grande \n",
    "#    e trovo gli indici di train dei più vicini\n",
    "# Attenzione: Tengo solo i primi K!\n",
    "k_neighbors = np.argsort(D, axis=0)[:K,:]\n",
    "#print(k_neighbors.shape)\n",
    "\n",
    "# 4. Controllo le etichette di questi K punti: devo trovare la più frequente:\n",
    "#     - Ottengo le etichette dei punti vicini\n",
    "#     - Trovo l'etichetta più frequente! Utilizzo la moda!\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html\n",
    "\n",
    "\n",
    "neighbors_labels = y_train[k_neighbors]\n",
    "prediction = stats.mode(neighbors_labels, axis=0)[0]\n",
    "#print(prediction.shape)\n",
    "\n",
    "# 5. Calcolo l'accuratezza\n",
    "accurancy = np.sum(prediction == y_test) / len(y_test)\n",
    "print('Accuratezza del classificatore: ' + '{0:.2f}'.format(accurancy * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit415c48a723454bdbaf7d9c6e9421d0c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}