\documentclass[11pt, a4paper, titlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[english, italian]{babel}
\usepackage[noadvisor]{frontespizio}
\usepackage{mathtools}
\usepackage[colorlinks=true, linkcolor=black]{hyperref}
\usepackage{graphicx, wrapfig, subcaption, setspace, booktabs}
\graphicspath{{References//}}
\usepackage[margin=1in]{geometry}
\usepackage{adjustbox}
\usepackage{tabls, tabularx}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{enumerate}
\usepackage{float}
\usepackage{cite}

\begin{document}

\begin{frontespizio}
\Margini{2.5cm}{3cm}{2.5cm}{3cm}
\Universita{Verona}
\Logo[4cm]{logo}
\Dipartimento{Informatica}
%\Facolta{Informatica}
\Corso[Laurea]{Ingegneria e scienze informatiche}
\Annoaccademico{2019--2020}
\Titoletto{Progetto di Teorie e Tecniche del Riconoscimento}
\Titolo{Food Recognition}
\Sottotitolo{}
%\NCandidato{Laureanda}
\Candidato[VR451051]{Alessia Bodini} 
\end{frontespizio}
\IfFileExists{\jobname-frn.pdf}{}{
\immediate\write18{pdflatex \jobname-frn}}
%\lstinputlisting{Relazione-frn.log}

%\title{Food Recognition}
%\author{Alessia Bodini}
%\date{\today}

%\maketitle
\tableofcontents
\newpage

% MOTIVAZIONI
\section{Motivazioni e fondamento logico}
Il seguente progetto si pone lo scopo di identificare una serie di cibi facendo uso di modelli visti durante il corso di studio (KNN, SVM e NN). Tale tipo di riconoscimento può risultare molto utile per quanto riguarda la classificazione di piatti in tutto il mondo, ad esempio per viaggiotori o stranieri che vogliono avere maggiori informazioni sul piatto o per coloro che sono interessati ad conoscere i valori nutrizionali del cibo proposto, il tutto con una sola foto. 

% STATO DELL'ARTE
\section{Stato dell'arte}
L'applicazione maggiormente conosciuta per quanto riguardo il riconoscimento di cibi è al momento \emph{Calorie Mama} \cite{calorie-mama}. Tale applicazione è disponibile per Apple e Android e permette non solo di riconoscere i cibi ma anche di mostrarne i valori nutrizionali e di far gestire all'utente le calorie assunte giornalmente e relativi programmi di fitness. La funzione di \textit{istant food recognition} viene alimentata da \textit{Food AI API} \cite{foodai} basata sulle ultime innovazioni in campo di deep learning e in grado di riconoscere ad oggi 756 cibi diversi (gran parte cibi tipici di Singapore). Ogni piatto viene poi legato a specifici valori nutrizionali che l'utente utilizza per controllare le proprie diete direttamente dall'app.

% OBBIETTIVI
\section{Obbiettivi}
Il mio progetto non si pone di superare i risultati già raggiunti dall'applicazione nè da \textit{Food AI API}, ma di eseguire un'analisi sulle migliori tecniche di classificazione conosciute e decretare la più efficiente tra queste. In particolare il mio lavoro si è concentrato sull'analisi di tre principali metodi per la classificazione: KNN (\textit{K-Nearest Neighbors}), SVM (\textit{Support Vector Machine}) e reti neurali. 

\pagebreak

% METODOLOGIA 
\section{Metodologia}
Il lavoro si è suddiviso nella ricerca di un dataset e relativa estrazione dei dati e delle features poi utilizzate e nell'implementazione di alcuni dei modelli di riconoscimento visti durante il corso. Si spiegano di seguito nei dettagli tali processi. 

% Ricerca del dataset
\subsection{Ricerca del dataset}
Il dataset scelto denominato \emph{Food-101} \cite{food-101} è disponibile sul sito \url{kaggle.com} e presenta un totale di 10100 fotografie di piatti e cibi diversi. In particolare, il dataset è suddiviso in 101 categorie di cibi, ognuna composta da 1000 foto. La classe di appartenza è deducibile dalla cartella in cui essa è contenuta. 

Per tutti e tre i metodi di riconoscimento usati si è fatto uso di un campione di sole 10 classi, prendendo 100 immagini ciascuna per la fase di training e 10 per quella di testing, ridimensionate in un formato 64x64. La scelta di questo insieme ridotto di immagini ha permesso di svolgere le operazioni in tempi relativamente brevi. Solo nel caso delle reti neurali si sono presi in considerazione per ogni categoria anche un training set di 750 immagini e un testing set di 250, prendendo le foto in input con due formati diversi 64x64 e 128x128. Negli altri due casi invece, si è visti da subito che l'utilizzo di un campione più grande portava spesso a peggiori risultati. 

% Estrazione delle features
\subsection{Estrazione delle features}
Per l'estrazione delle features si è fatto uso di una rete neurale disponibili tra i modelli di Torchvision e già richiamata tramite il file \emph{resnet.py} rilasciato per questo progetto. Tale modello è il ResNet-50, definito a partire dalla ricerca \emph{Deep Residual Learning for Image Recognition} \cite{resnet50}.

ResNet-50 è stato usato per i primi due metodi di riconoscimento usati (KNN e SVM), mentre alla rete neurale definita successivamente sono state date direttamente in pasto le immagini del dataset (nel formato specificato sopra).
 
% Metodi di riconoscimento
\subsection{Metodi di riconoscimento usati}
I metodi di riconoscimento implementati sono i seguenti. 

\paragraph{KNN}
Il metodo dei \emph{K-Nearest Neighbors} è stato costruito utilizzando diversi tipi di metriche e un diverso numero di vicini (\emph{K}) considerati per l'attribuzione a una certa categoria. In particolare si è fatto uso delle seguenti metriche per il calcolo delle distanze tra le features:
\begin{itemize}
    \item distanza euclidea: 
    \begin{math} \left \| u - v \right \| \end{math};
    \item distanza di Minkowski:
    \begin{math} \left \| u - v \right \|_p \end{math};
    \item distanza del coseno: 
    \begin{math} 1 - \frac{u \cdot v}{\left \| u \right \|_2 \cdot \left \| v \right \|_2} \end{math};
    \item correlazione: 
    \begin{math} 1 - \frac{(u - \bar u) \cdot (v - \bar v)}{\left \| (u - \bar u) \right \|_2 \cdot \left \| (v - \bar v) \right \|_2} \end{math};
\end{itemize}
Per ognuna delle precedente se ne è calcolata l'efficienza per K pari a 1, 3 e 7.

\paragraph{SVM}
Per l'implementazione della \emph{Support Vector Machine} si sono presi in considerazione anche in questo caso di kernel diversi:
\begin{itemize}
    \item lineare; 
    \item polinomiale, con grado pari a 3, 5 e 7;
    \item RBF \emph{Radial Basis Function}, usando diversi valori per gamma ($\frac{1}{n\_features \cdot set.var()}$ se posta uguale a \emph{auto} o $\frac{1}{n\_features \cdot set.var()}$ se posta su \emph{scale}) e di C ($0.1, 1, 10$).
\end{itemize}
Per tutti i casi si è testato il modello su 10, 100 e 1000 iterazioni totali.

\paragraph{NN}
La rete nurale è stato creata ad hoc per il dataset e comprende 6 diversi strati:
\begin{enumerate}
    \item convoluzione 2D con kernel di dimensione 3x3, passando da 3 canali in input (RGB) a 6 finali;
    \item \emph{max-pooling} di dimensione 2x2;
    \item seconda convoluzione 2D con uguale kernel (3x3), passando da 6 canali in input a 16 in output;
    \item trasformazione lineare che prende come features in input l'insieme dei valori che riguardano l'immagine come finora è stata modificata, cioè con $16 \times 14$ (o 30) $\times 14$ (o 30) ($numero di canali \times altezza \times larghezza$), che confluiscono in 2048 features in output;
    \item seconda trasformazione lineare che riduce le features in 1024;
    \item terza e ultima trasformazione lineare che da 1024 features passa a sole 10 che rappresentano il numero di classi finali di appartenza. La feature che presenta il valore più alto sarà identificata come la classe di appartenza.
\end{enumerate}
Tale configurazione è stata ispirata da quella presente in nel tutorial di PyTorch: \href{https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html}{Training a classifier}. Il tasso di apprendimento è stato impostato tra 0.001 e 0.01 e il numero di batch a 4. La fase di addestramento è stata fatta proseguire per 2, 5 e 10 epoche. 

\section{Esperimenti e risultati raggiunti}
In generale, gli esperimenti eseguiti non hanno raggiunto le aspettative. Il miglior valore di accuratezza, raggiunto tramite il metodo dei \emph{K-Nearest Neighbors}, è stato del 20\%, con valori di precisione e recall rispettivamente uguali a 0.33 e 0.34).

\medskip
Per ogni metodo in particolare sono stati conseguiti i seguenti risultati. 

\subsection{KNN}
\begin{table}[h]
    \centering
    \begin{tabular}{|l||*{5}{c|}} \hline
    \toprule
    \diagbox{Metric}{K} & 1 & 3 & 7 \\ \hline
    \midrule
    Euclidean               & 18\% & 17\% & 9\%  \\ \hline
    Minkowski               & 18\% & 17\% & 9\%  \\ \hline
    Cosine                  & 20\% & 19\% & 12\% \\ \hline
    Correlation             & 19\% & 16\% & 14\% \\ \hline
    \end{tabular}
    \caption{Risultati ottenuti per il modello KNN.}
\end{table}

\subsection{SVM}
Nel caso della \emph{Support Vector Machine} si distinguono i rusltati ottenuti con kernel lineare e polinomiale (praticamente uguali per grado pari a 3, 5 o 7) e quelli raggiunti tramite RBF (\emph{Radial Basis Function}), suddivisi in base ai valori scelti per gamma e per C.

\begin{table}[h]
    \centering
    \begin{tabular}{|l||*{5}{c|}} \hline
    \toprule
    \diagbox{Kernel}{Iterations} & 10 & 100 & 1000 \\ \hline
    \midrule
    Linear               & 10\% & 14\% & 15\%  \\ \hline
    Polynomial           & 10\% & 7\%  & 5\%   \\ \hline
    \end{tabular}
    \caption{Risultati ottenuti con la SVM con kernel lineare e polinomiale.}
\end{table}

\section{Conclusioni}
4
\pagebreak
\bibliography{Bibliografia}{}
\bibliographystyle{plain}

\end{document}
